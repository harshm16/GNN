{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def read_ground_truth(filename):\n",
    "   \n",
    "    # all_labels = []\n",
    "   \n",
    "    with open(filename,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        # print(lines)\n",
    "    # return all_labels\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the groundtruth file\n",
    "label_data = read_ground_truth(r\"groundtruth-events.txt\")\n",
    "\n",
    "dict_labels = {}\n",
    "\n",
    "for labels in label_data:\n",
    "    \n",
    "    columns = labels.split()\n",
    "    labels_list = []\n",
    "    for idx, value in enumerate(columns):\n",
    "        \n",
    "        if idx ==0:\n",
    "            image_name = value.split(\"/\")[1]\n",
    "\n",
    "        else:\n",
    "            values = float(value)\n",
    "            labels_list.append(values)\n",
    "        \n",
    "    dict_labels[image_name] = labels_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_dataset(img_folder,dict_labels):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for image_x in os.listdir(img_folder):\n",
    "        # print(image_x)\n",
    "      \n",
    "        if image_x in dict_labels.keys():\n",
    "            class_name.append(dict_labels[image_x])\n",
    "        image_path = os.path.join(img_folder, image_x)\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        gray= cv2.cvtColor(image,cv2.COLOR_BGR2RGB)    \n",
    "\n",
    "        gray_image=np.array(gray)\n",
    "\n",
    "        img_data_array.append(gray_image)\n",
    "        \n",
    "\n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset using images\n",
    "img_array, ground_labels = create_dataset(r\"images\",dict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_img_array = []\n",
    "new_ground_labels = []\n",
    "\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    short_img_array.append(img_array[i][:299])\n",
    "    new_ground_labels.append(ground_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_five_d_list = []\n",
    "\n",
    "for x in range(len(short_img_array)):\n",
    "    #sample points above a certain threshold\n",
    "    thresh = 70\n",
    "    \n",
    "    intensity = cv2.cvtColor(short_img_array[x], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    data = short_img_array[x][intensity>thresh]\n",
    "\n",
    "    coords = np.argwhere(intensity>thresh)\n",
    "\n",
    "    five_dim_list = []\n",
    "    \n",
    "    #randomly choose 53 points\n",
    "    chosen_cords_x = np.random.choice(coords[:,0], size=53, replace=False)\n",
    "    chosen_cords_y = np.random.choice(coords[:,1], size=53, replace=False)\n",
    "\n",
    "\n",
    "    for each in range(len(chosen_cords_x)):\n",
    "\n",
    "        r, g, b = short_img_array[x][chosen_cords_x[each]][chosen_cords_y[each]]\n",
    "        five_d_list = [chosen_cords_x[each]/299,chosen_cords_y[each]/299,r/255,g/255,b/255]\n",
    "\n",
    "        five_dim_list.append(np.array(five_d_list))\n",
    " \n",
    "\n",
    "    all_images_five_d_list.append(np.array(five_dim_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_five_d_list = np.array(all_images_five_d_list)   \n",
    "new_ground_labels = np.array(new_ground_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images_five_d_list, new_ground_labels, train_size=0.8, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.from_numpy(X_train.astype(np.float))\n",
    "targets = torch.from_numpy(y_train.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "\n",
    "\n",
    "batch_size_training = 27\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size_training, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = torch.from_numpy(X_test)\n",
    "targets_test = torch.from_numpy(y_test)\n",
    "\n",
    "dataset_test = TensorDataset(inputs_test, targets_test)\n",
    "\n",
    "batch_size = 17\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single run with binary codes as kernel\n",
    "epoch_list = [10, 134, 259, 383, 508, 632, 757, 882, 1006, 1131, 1255, 1380, 1505, 1629, 1754, 1878, 2003, 2127, 2252, 2377, 2501, 2626, 2750, 2875, 3000]\n",
    "\n",
    "\n",
    "testing_loss_tmd = []\n",
    "\n",
    "#set value of alpha \n",
    "delta_t = 0.1\n",
    "\n",
    "def mse_loss_withtmd(predictions, targets, tmd):\n",
    "    difference = predictions - targets + (tmd * delta_t)\n",
    "    return torch.sum(difference * difference)/ difference.numel()\n",
    "\n",
    "def signal_to_noise_loss_withtmd(predictions, targets,tmd):\n",
    "    difference = predictions - targets + (tmd * delta_t)\n",
    "    return torch.sum(difference * difference)/ torch.sum(targets * targets)\n",
    "\n",
    "w = torch.randn(7, 265, requires_grad=True)\n",
    "b = torch.randn(7, requires_grad=True)\n",
    "\n",
    "\n",
    "D_epsilon_tilde_hyper = torch.nn.Parameter(torch.FloatTensor([0.1]))\n",
    "\n",
    "def model(X):\n",
    "    return X @ w.t() + b\n",
    "\n",
    "def tmd_layer(input,batch_size):\n",
    "\n",
    "    rff_w = torch.normal(0, 1, size=(265, 1))\n",
    "\n",
    "    rff_b = torch.normal(0, 2.0 * np.pi, size=(batch_size, 1))\n",
    "\n",
    "    Qt_x = torch.cos(torch.matmul(input.reshape(batch_size,265).double(), rff_w.double())+ rff_b )\n",
    "\n",
    "    t= torch.FloatTensor(batch_size, 1).uniform_(-2, 2)\n",
    "\n",
    "    sgn = Qt_x + t\n",
    "\n",
    "    sgn.apply_(lambda x: -1 if x < 0 else 1)\n",
    "\n",
    "\n",
    "    sgn.apply_(lambda x: (1 + x)/2)\n",
    "\n",
    "    K_epsilon = torch.cdist(sgn, sgn, p=0)\n",
    "\n",
    "\n",
    "    epsilon = 0.25\n",
    "\n",
    "    q_epsilon_tilde = (K_epsilon).sum(dim=1)\n",
    "\n",
    "    D_epsilon_tilde = torch.diag_embed(D_epsilon_tilde_hyper / q_epsilon_tilde)\n",
    "\n",
    "    K_tilde  = torch.matmul(K_epsilon, D_epsilon_tilde)\n",
    "\n",
    "    D_tilde = torch.diag_embed(K_tilde.sum(dim=1))\n",
    "\n",
    "    L =  1 / epsilon * (torch.inverse(D_tilde).matmul(K_tilde)) - torch.eye(K_tilde.shape[1])      \n",
    "    \n",
    "    x_l = torch.matmul(torch.transpose(L.float(),0,1), input.reshape(batch_size,265).float())\n",
    "\n",
    "    xlw = torch.matmul(w, torch.transpose(x_l,0,1))\n",
    "\n",
    "    final_L = torch.div(torch.transpose(xlw,0,1),batch_size)\n",
    "\n",
    "    return final_L  \n",
    "\n",
    "\n",
    "for i in range(3000):\n",
    "    # Iterate through training dataloader\n",
    "    for x,y in train_loader:\n",
    "\n",
    "        preds = model(x.reshape(27,265).float())\n",
    "\n",
    "        #Correction using tmd-layer\n",
    "        tmd_layer_L = tmd_layer(x,27)\n",
    "\n",
    "        loss = signal_to_noise_loss_withtmd(preds, y, tmd_layer_L)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w -= w.grad *1e-2\n",
    "            b -= b.grad * 1e-2\n",
    "       \n",
    "            D_epsilon_tilde_hyper -= D_epsilon_tilde_hyper * 1e-2\n",
    "            # Set the gradients to zero\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "\n",
    "            D_epsilon_tilde_hyper.grad.zero_()\n",
    "            \n",
    "\n",
    "    #test for epochs in the epoch_list\n",
    "    if i in epoch_list:\n",
    "\n",
    "        epochs_test = 1\n",
    "        batch_size_testing = 17\n",
    "\n",
    "        for x_test,y_test in test_loader:\n",
    "                        \n",
    "            tmd_layer_L_test = tmd_layer(x_test,batch_size_testing)\n",
    "            \n",
    "            #make prediction\n",
    "            preds = model(x_test.reshape(batch_size_testing,265).float())\n",
    "\n",
    "            # Get the loss and perform backpropagation\n",
    "            loss = signal_to_noise_loss_withtmd(preds, y_test, tmd_layer_L_test)\n",
    "\n",
    "        testing_loss_tmd.append(loss.item())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_3.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "da9aa12b0836bb12fcb825e24bcc2589f3a3af693bdb142976e3cb8df3f4e088"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
